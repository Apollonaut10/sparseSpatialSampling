{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3949356f-027f-4af6-8f6d-c7291cc4956d",
   "metadata": {},
   "source": [
    "# Tutorial 2: OAT15 at high speed stall conditions\n",
    "## flowTorch workshop 29.09.2025 - 02.10.2025\n",
    "\n",
    "### Outline\n",
    "here: \n",
    "- loading data from HDF5 instead of OpenFOAM format\n",
    "- then use different geoemtry objects\n",
    "- use `N_cells_max` as stopping criterion instead of approximation of the metric\n",
    "\n",
    "need to have the geometry and data, otherwise replacce with own geometries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e7de4d-8175-4adb-b70f-abcb74ca8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: TecplotDataloader can't be loaded. Most likely, the 'paraview' module is missing.\n",
      "Refer to the installation instructions at https://github.com/FlowModelingControl/flowtorch\n",
      "If you are not using the TecplotDataloader, ignore this warning.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "\n",
    "from stl import mesh\n",
    "from os.path import join\n",
    "from os import environ, system\n",
    "\n",
    "environ[\"sparseSpatialSampling\"] = \"..\"\n",
    "sys.path.insert(0, environ[\"sparseSpatialSampling\"])\n",
    "\n",
    "from sparseSpatialSampling.export import ExportData\n",
    "from sparseSpatialSampling.sparse_spatial_sampling import SparseSpatialSampling\n",
    "from sparseSpatialSampling.geometry import CubeGeometry, GeometryCoordinates2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d256c79c-6986-4a63-9b70-d07d43edbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_airfoil_from_stl_file(_load_path: str, _name: str = \"oat15.stl\", sf: float = 1.0, dimensions: str = \"xy\",\n",
    "                               x_offset: float = 0.0, y_offset: float = 0.0, z_offset: float = 0.0):\n",
    "    \"\"\"\n",
    "    Example function for loading airfoil geometries stored as STL file and extract an enclosed 2D-area from it.\n",
    "    Important Note:\n",
    "\n",
    "        the structure of the coordinates within the stl files depends on the order the blocks are exported from\n",
    "        Paraview; the goal is to form an enclosed area, through which we can draw a polygon. Therefore, the way of\n",
    "        loading and sorting the data depends on the stl file. For an airfoil, the data can be sorted as:\n",
    "\n",
    "            TE -> via suction side -> LE -> via pressure side -> TE\n",
    "\n",
    "        It is helpful to export the airfoil geometry without a training edge and close it manually by connecting the\n",
    "        last points from pressure to suction side\n",
    "\n",
    "    :param _load_path: path to the STL file\n",
    "    :param _name: name of the STL file\n",
    "    :param sf: scaling factor, in case the airfoil needs to be scaled\n",
    "    :param dimensions: which plane (orientation) to extract from the STL file\n",
    "    :param x_offset: offset for x-direction, in case the airfoil should be shifted in x-direction\n",
    "    :param y_offset: offset for y-direction, in case the airfoil should be shifted in y-direction\n",
    "    :param z_offset: offset for z-direction, in case the airfoil should be shifted in z-direction\n",
    "    :return: coordinates representing a 2D-airfoil as enclosed area\n",
    "    \"\"\"\n",
    "    # mapping for the coordinate directions\n",
    "    dim_mapping = {\"x\": 0, \"y\": 1, \"z\": 2}\n",
    "    dimensions = [dim_mapping[d] for d in dimensions.lower()]\n",
    "\n",
    "    # load stl file\n",
    "    stl_file = mesh.Mesh.from_file(_load_path)\n",
    "\n",
    "    # scale the airfoil to the original size used in CFD and shift if specified\n",
    "    stl_file.x = stl_file.x * sf + x_offset\n",
    "    stl_file.y = stl_file.y * sf + y_offset\n",
    "    stl_file.z = stl_file.z * sf + z_offset\n",
    "\n",
    "    # stack the coordinates (zeros column, because values are the same in all columns)\n",
    "    coord_af = np.stack([stl_file.x[:, 0], stl_file.y[:, 0], stl_file.z[:, 0]], -1)\n",
    "\n",
    "    # remove duplicates without altering the order -> required, otherwise the number of points is very large\n",
    "    coord_af = coord_af[:, dimensions]\n",
    "    _, idx = np.unique(coord_af, axis=0, return_index=True)\n",
    "    coord_af = coord_af[np.sort(idx)]\n",
    "\n",
    "    return coord_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d7a60e-6d52-4f94-8aca-0bbb737138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the CFD data and settings\n",
    "load_path = join(\"..\", \"data\", \"2D\", \"OAT15\")\n",
    "save_path = join(\"..\", \"run\", \"tutorials\", \"tutorial_2\")\n",
    "\n",
    "# here we want to use the N_cells_max stopping criterion\n",
    "n_cells_max = 25000\n",
    "save_name = f\"OAT15_{n_cells_max}_cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f85ae13-877d-4662-b2af-6d8abd4a4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the coordinates of the original grid used in CFD\n",
    "xz = pt.load(join(load_path, \"vertices_and_masks.pt\"))\n",
    "\n",
    "# load the Mach nummber field of the original CFD data\n",
    "field = pt.load(join(\"..\", \"data\", \"2D\", \"OAT15\", f\"ma_large_every10.pt\"))\n",
    "\n",
    "# compute the metric, we want to resolve the buffet, so it make sense to use the std(Ma)\n",
    "metric = pt.std(field, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ebcd3a-f6b8-4109-b0fd-fce80567220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the airfoil geometry of the leading airfoil from an STL file\n",
    "oat15 = load_airfoil_from_stl_file(join(load_path, \"oat15_airfoil_no_TE.stl\"), dimensions=\"xz\")\n",
    "\n",
    "# load the rear NACA airfoil\n",
    "naca = load_airfoil_from_stl_file(join(load_path, \"naca_airfoil_no_TE.stl\"), dimensions=\"xz\")\n",
    "\n",
    "# define the boundaries for the domain and assemble the geometry objects\n",
    "xz = pt.stack([xz[f\"x_large\"], xz[f\"z_large\"]], dim=-1)\n",
    "bounds = [[pt.min(xz[:, 0]).item(), pt.min(xz[:, 1]).item()], [pt.max(xz[:, 0]).item(), pt.max(xz[:, 1]).item()]]\n",
    "\n",
    "geometry = [CubeGeometry(\"domain\", True, bounds[0], bounds[1]),\n",
    "            GeometryCoordinates2D(\"OAT15\", False, oat15, refine=True),\n",
    "            GeometryCoordinates2D(\"NACA\", False, naca, refine=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5320ef-80e9-4980-a499-1f27ae7f98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corresponding write times\n",
    "times = pt.load(join(load_path, \"oat15_tandem_times.pt\"))[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78aeb38-2706-4909-ab51-c4bdcc36c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-14 11:22:07] INFO     \n",
      "\tSelected settings:\n",
      "\t\t_pre_select          :\tFalse\n",
      "\t\t_n_jobs              :\t4\n",
      "\t\t_max_delta_level     :\tFalse\n",
      "\t\t_geometry            :\t['domain', 'OAT15', 'NACA']\n",
      "\t\t_min_metric          :\t0.75\n",
      "\t\t_n_cells_max         :\t25000\n",
      "\t\t_min_level           :\t5\n",
      "\t\t_cells_per_iter_start:\t245\n",
      "\t\t_cells_per_iter_end  :\t245\n",
      "\t\t_cells_per_iter      :\t245\n",
      "\t\t_cells_per_iter_last :\t1000000000.0\n",
      "\t\t_reach_at_least      :\t0.75\n",
      "\t\t_n_dimensions        :\t2\n",
      "\t\t_n_cells_orig        :\t245568\n",
      "\t\t_relTol              :\t0.001\n",
      "[2025-08-14 11:22:07] INFO     Starting refinement:\n",
      "\tStarting iteration no. 0, N_cells = 1\n",
      "\tStarting iteration no. 1, N_cells = 4\n",
      "\tStarting iteration no. 2, N_cells = 8\n",
      "\tStarting iteration no. 3, N_cells = 32\n",
      "\tStarting iteration no. 4, N_cells = 96\n",
      "[2025-08-14 11:22:12] INFO     Finished uniform refinement.\n",
      "[2025-08-14 11:22:12] INFO     Starting adaptive refinement.\n",
      "\tStarting iteration no. 0, N_cells = 320\n",
      "\tStarting iteration no. 1, N_cells = 1055\n",
      "\tStarting iteration no. 2, N_cells = 1775\n",
      "\tStarting iteration no. 3, N_cells = 2492\n",
      "\tStarting iteration no. 4, N_cells = 3184\n",
      "\tStarting iteration no. 5, N_cells = 3915\n",
      "\tStarting iteration no. 6, N_cells = 4650\n",
      "\tStarting iteration no. 7, N_cells = 5375\n",
      "\tStarting iteration no. 8, N_cells = 6095\n",
      "\tStarting iteration no. 9, N_cells = 6819\n",
      "\tStarting iteration no. 10, N_cells = 7537\n",
      "\tStarting iteration no. 11, N_cells = 8260\n",
      "\tStarting iteration no. 12, N_cells = 8981\n",
      "\tStarting iteration no. 13, N_cells = 9701\n",
      "\tStarting iteration no. 14, N_cells = 10428\n",
      "\tStarting iteration no. 15, N_cells = 11159\n",
      "\tStarting iteration no. 16, N_cells = 11888\n",
      "\tStarting iteration no. 17, N_cells = 12621\n",
      "\tStarting iteration no. 18, N_cells = 13348\n",
      "\tStarting iteration no. 19, N_cells = 14071\n",
      "\tStarting iteration no. 20, N_cells = 14797\n",
      "\tStarting iteration no. 21, N_cells = 15528\n",
      "\tStarting iteration no. 22, N_cells = 16254\n",
      "\tStarting iteration no. 23, N_cells = 16983\n",
      "\tStarting iteration no. 24, N_cells = 17711\n",
      "\tStarting iteration no. 25, N_cells = 18443\n",
      "\tStarting iteration no. 26, N_cells = 19176\n",
      "\tStarting iteration no. 27, N_cells = 19906\n",
      "\tStarting iteration no. 28, N_cells = 20636\n",
      "\tStarting iteration no. 29, N_cells = 21353\n",
      "\tStarting iteration no. 30, N_cells = 22084\n",
      "\tStarting iteration no. 31, N_cells = 22812\n",
      "\tStarting iteration no. 32, N_cells = 23537\n",
      "\tStarting iteration no. 33, N_cells = 24262\n",
      "\tStarting iteration no. 34, N_cells = 24990\n",
      "[2025-08-14 11:22:23] INFO     Finished adaptive refinement.\n",
      "[2025-08-14 11:22:23] INFO     Starting geometry refinement.\n",
      "[2025-08-14 11:22:23] INFO     Starting refining geometry OAT15.\n",
      "[2025-08-14 11:22:28] INFO     Starting refining geometry NACA.\n",
      "[2025-08-14 11:22:30] INFO     Finished geometry refinement.\n",
      "[2025-08-14 11:22:30] INFO     Starting renumbering final mesh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: TecplotDataloader can't be loaded. Most likely, the 'paraview' module is missing.\n",
      "Refer to the installation instructions at https://github.com/FlowModelingControl/flowtorch\n",
      "If you are not using the TecplotDataloader, ignore this warning.\n",
      "Warning: TecplotDataloader can't be loaded. Most likely, the 'paraview' module is missing.\n",
      "Refer to the installation instructions at https://github.com/FlowModelingControl/flowtorch\n",
      "If you are not using the TecplotDataloader, ignore this warning.\n",
      "Warning: TecplotDataloader can't be loaded. Most likely, the 'paraview' module is missing.\n",
      "Refer to the installation instructions at https://github.com/FlowModelingControl/flowtorch\n",
      "If you are not using the TecplotDataloader, ignore this warning.\n",
      "Warning: TecplotDataloader can't be loaded. Most likely, the 'paraview' module is missing.\n",
      "Refer to the installation instructions at https://github.com/FlowModelingControl/flowtorch\n",
      "If you are not using the TecplotDataloader, ignore this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-14 11:22:35] INFO     Finished refinement in 27.5825 s \n",
      "\t\t\t\t\t\t\t\t(35 iterations).\n",
      "\t\t\t\t\t\t\t\tTime for uniform refinement: 5.1138 s\n",
      "\t\t\t\t\t\t\t\tTime for adaptive refinement: 11.2853 s\n",
      "\t\t\t\t\t\t\t\tTime for geometry refinement: 6.6494 s\n",
      "\t\t\t\t\t\t\t\tTime for renumbering the final mesh: 4.5298 s\n",
      "\t\t\t\t\t\t\t\t\n",
      "                                    Number of cells: 28919\n",
      "                                    Minimum ref. level: 6\n",
      "                                    Maximum ref. level: 12\n",
      "                                    Captured metric of original grid: 56.29 %\n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "# instantiate an S^3 object\n",
    "s_cube = SparseSpatialSampling(xz, metric, geometry, save_path, save_name, \"OAT15\", n_jobs=4, n_cells_max=n_cells_max,\n",
    "                               write_times=times.tolist())\n",
    "\n",
    "# execute S^3\n",
    "s_cube.execute_grid_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b79582-46a6-44ec-9473-b20e2840008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-14 11:22:35] INFO     Starting interpolation and export of field Ma.\n",
      "[2025-08-14 11:22:39] INFO     Writing HDF5 file for field Ma.\n",
      "[2025-08-14 11:22:39] INFO     Writing XDMF file for file OAT15_25000_cells.h5\n",
      "[2025-08-14 11:22:39] INFO     Finished export of field Ma in 4.969s.\n"
     ]
    }
   ],
   "source": [
    "# create export instance, export all fields into the same HFD5 file and create single XDMF from it\n",
    "# HDF5 may throws an error when running multiple notebooks in parallel. In that case close the otehr notebooks and restart the Kernel\n",
    "export = ExportData(s_cube)\n",
    "export.export(xz, field.unsqueeze(1), \"Ma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162baf69-45a4-4bdb-972f-3280ce34276b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
