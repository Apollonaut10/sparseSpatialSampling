"""

    - Dataloader: class for loading the data from the HDF5 output file from S^3 and assembling the data matrix
    - Datawriter: implements a Datawriter class for writing the data generated by S^3 to HDF5 file
    - XDMFwriter: implements class for generating an XDMF file based on a given HDF5 file from S^3
"""
import logging
import torch as pt

from h5py import File
from os.path import join, isfile
from typing import Union, List, Dict

from .const import DATA, GRID, CONST, CENTERS, VERTICES, FACES

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class Dataloader:
    """
    class for loading the data from the HDF5 output file from S^3 and assembling the data matrix
    """
    def __init__(self, load_path: str, file_name: str, dtype: pt.dtype = pt.float32):
        """
        implements a DataLoader class for conveniently loading the HDF5 file generated by S^3

        :param load_path: path to the HDF5 file
        :type load_path: str
        :param file_name: name of the HDF5 file
        :type file_name: str
        :param dtype: the type of the tensor, default is set to float32 (single precision)
        :type dtype: pt.dtype
        """
        # create a file object
        self._load_path = load_path
        self._file_name = file_name
        self._dtype = dtype

        # load some values we may need, we always have to close the file after reading, otherwise we can't access it
        # later for writing (or sth. else)
        with File(join(self._load_path, self._file_name), "r") as f:
            self._n_cells = f.get(f"{GRID}/{CENTERS}")[()].shape[0]
            self._n_dimensions = f.get(f"{GRID}/{CENTERS}")[()].shape[1]
            self._size_initial_cell = f.get(f"{CONST}/size_initial_cell")[()]

        # placeholders for properties which are only loaded if requested
        self._write_times = None
        self._weights = None  # cell areas (2D) / volumes (3D)
        self._levels = None
        self._field_names = None

        # properties of the grid
        self._vertices = None
        self._faces = None
        self._nodes = None

    @property
    def write_times(self) -> List[str]:
        """
        load all available time steps present in the HDF5 file, the time steps at which a specific field is present are
        stored in the 'field_names' property.

        :return: available write times
        :rtype list
        """
        if self._write_times is None:
            with File(join(self._load_path, self._file_name), "r") as f:
                if DATA in f.keys():
                    self._write_times = list(f.get(f"{DATA}").keys())

        return self._write_times

    @property
    def weights(self) -> pt.Tensor:
        """
        load and compute the cell areas (2d) / volumes (3D) of the grid

        :return: cell areas / volumes
        :rtype: pt.Tensor
        """
        if self._weights is None:
            self._compute_cell_area()

        return self._weights

    @property
    def vertices(self) -> pt.Tensor:
        """
        load the cell centers of the grid

        :return: cell centers of the grid
        :rtype: pt.Tensor
        """
        if self._vertices is None:
            with File(join(self._load_path, self._file_name), "r") as f:
                self._vertices = pt.from_numpy(f.get(f"{GRID}/{CENTERS}")[()])

        return self._vertices

    @property
    def nodes(self) -> pt.Tensor:
        """
        load the cell nodes of the grid

        :return: cell nodes of the grid
        :rtype: pt.Tensor
        """
        if self._nodes is None:
            with File(join(self._load_path, self._file_name), "r") as f:
                self._nodes = pt.from_numpy(f.get(f"{GRID}/{VERTICES}")[()])

        return self._nodes

    @property
    def faces(self) -> pt.Tensor:
        """
        load the cell faces of the grid

        :return: idx cell faces of the grid
        :rtype: pt.Tensor
        """
        if self._faces is None:
            with File(join(self._load_path, self._file_name), "r") as f:
                self._faces = pt.from_numpy(f.get(f"{GRID}/{FACES}")[()])

        return self._faces

    @property
    def field_names(self) -> dict:
        """
        create a dictionary containing the available fields as a list for each available time step, the time steps are
        the keys while the available fields are the values for each key

        :return: dict with available fields for each available time step
        :rtype: Dict[list]
        """
        if self._field_names is None:
            # we can't use CENTERS, because CENTERS only stands for the cell centers of the grid; the location of the
            # field is marked as center or vertices
            with File(join(self._load_path, self._file_name), "r") as f:
                self._field_names = {k: [f.split("_")[0] for f in f[f"{DATA}/{k}"].keys() if f.endswith("center")]
                                     for k in f[DATA].keys()}

        return self._field_names

    @property
    def levels(self) -> pt.Tensor:
        """
        load the cell levels of the grid

        :return: cell levels of the grid
        :rtype: pt.Tensor
        """
        if self._levels is None:
            with File(join(self._load_path, self._file_name), "r") as f:
                self._levels = pt.from_numpy(f.get(f"{CONST}/levels")[()]).squeeze()

        return self._levels

    @property
    def load_path(self) -> str:
        """
        get the current load path

        :return: current load path
        :rtype: str
        """
        return self._load_path

    @load_path.setter
    def load_path(self, value: str) -> None:
        """
        Set a new load path, this automatically resets the properties to avoid inconsistencies

        :return: None
        """
        self._load_path = value
        self._reset()

    @property
    def file_name(self) -> str:
        """
        get the current file name

        :return: current file name
        :rtype: str
        """
        return self._file_name

    @file_name.setter
    def file_name(self, value: str) -> None:
        """
        Set a new file name, this automatically resets the properties to avoid inconsistencies

        :return: None
        """
        self._file_name = value
        self._reset()

    def _reset(self) -> None:
        """
        Reset the properties of the class to avoid inconsistencies

        :return: None
        """
        with File(join(self._load_path, self._file_name), "r") as f:
            self._n_cells = f.get(f"{GRID}/{CENTERS}")[()].shape[0]
            self._n_dimensions = f.get(f"{GRID}/{CENTERS}")[()].shape[1]
            self._size_initial_cell = f.get(f"{CONST}/size_initial_cell")[()]
        self._write_times = None
        self._weights = None
        self._levels = None
        self._field_names = None
        self._vertices = None

    def _compute_cell_area(self) -> None:
        """
        Compute the cell areas (2d) / volumes (3D) of the grid

        :return: None
        """
        self._weights = (1 / pow(2, self._n_dimensions) * pow(self._size_initial_cell / pow(2, self.levels),
                                                              self._n_dimensions)).squeeze()

    def load_snapshot(self, field_name: Union[List[str], str],
                      write_times: Union[str, List[str]] = None) -> Union[List[pt.Tensor], pt.Tensor]:
        """
        load the snapshots for the given field(s) and time steps

        :param field_name: field name for which the data matrix should be created
        :type field_name: str
        :param write_times: time steps for which the data matrix should be created, if 'None' then all available time
                            steps will be used
        :type write_times: Union[str, List[str]]
        :return: either data matrix containing the snapshots as: [N_cells, N_dimensions, N_snapshots] (vector field) and
                 [N_cells, N_snapshots] (scalar field) or list with data matrices (if multiple fields should be loaded)
        :rtype: Union[List[pt.Tensor], pt.Tensor]
        """
        if write_times is None:
            write_times = self.write_times

        if type(write_times) is str:
            write_times = [write_times]
        if type(field_name) is str:
            field_name = [field_name]

        # create fiel object and empty list for storing the data matrices
        _file = File(join(self._load_path, self._file_name), "r")
        _dm = []

        for f in field_name:
            # get the shape of the field (scalar / vector field)
            shape = _file.get(f"{DATA}/{write_times[0]}/{f}_center")[()].shape

            # allocate the data matrix accordingly
            if len(shape) == 1:
                _data_matrix = pt.zeros((self._n_cells, len(write_times)), dtype=self._dtype)
            else:
                _data_matrix = pt.zeros((shape[0], shape[1], len(write_times)), dtype=self._dtype)

            # assemble the data matrix for the given time steps
            for i, k in enumerate(write_times):
                if len(shape) == 1:
                    _data_matrix[:, i] = pt.from_numpy(_file.get(f"{DATA}/{k}/{f}_center")[()])
                else:
                    _data_matrix[:, :, i] = pt.from_numpy(_file.get(f"{DATA}/{k}/{f}_center")[()])

            _dm.append(_data_matrix)

        # close the file
        _file.close()

        return _dm[0] if len(_dm) == 1 else _dm


class Datawriter:
    """
    Implements a Datawriter class for writing the data generated by S^3 to HDF5 file and create XDMF file for loading
    into paraview (or other) based on the contents of the HDF5 file.
    Inspired and partially adopted by the flowtorch Datawriter, which can be found in

    https://github.com/FlowModelingControl/flowtorch/blob/main/flowtorch/data/hdf5_file.py
    """

    def __init__(self, file_path: str, file_name: str, mode: str = "w", mixed: bool = False):
        """
        initialize the h5py file writer

        :param file_path: path where the HDF5 file should be saved to
        :type file_path: str
        :param file_name: name of the HDF5 file (incl. ending, e.g., data.h5)
        :type file_name: str
        :param mode: either 'w' for creating a new file (and overwriting existing files with the same name) or 'a' to
                     append to an existing HDF file. The mode can be changed once the object is instantiated.
        :type mode: str
        :param mixed: flag that the grid ist from type 'Mixed' (in case of unstructured grid which wasn't created with
                      S^3); only relevant for writing the XDMF file
        :type mixed: bool
        """
        self._file_name = file_name
        self._mode = mode
        self._mixed = mixed
        self._file_path = file_path
        self._file = File(join(self._file_path, self._file_name), self._mode)

        # allocate groups for DATA, GRID & CONST if they don't exist yet, otherwise load them
        self._data = None if DATA not in self._file.keys() else self._file[DATA]
        self._const = None if CONST not in self._file.keys() else self._file[CONST]
        self._grid = None if GRID not in self._file.keys() else self._file[GRID]

    def close(self) -> None:
        """
        Close the HDF writer

        :return: None
        """
        self._file.close()

    def write_grid(self, loader: Dataloader) -> None:
        """
        Write the grid for a new HDF5 file based on a given dataloader

        :param loader: Dataloder instance containing the path to the HDF file from which the grid should be loaded
        :type loader: Dataloader
        :return: None
        """
        self.write_data("centers", group="grid", data=loader.vertices)
        self.write_data("vertices", group="grid", data=loader.nodes)
        self.write_data("faces", group="grid", data=loader.faces)

    def write_data(self, name: str, data: any, group: str = "constant",
                   time_step: Union[int, float, str] = None) -> None:
        """
        write data to HDF5 file

        :param name: name of the dataset which should be created
        :type name: str
        :param data: the data to write
        :type data: any
        :param group: the group the data should be written to; available groups are:
                            'constant': arbitrary values and fields which have no time dependency,
                            'grid': the grid containing the datasets 'centers', 'vertices' and 'faces' from S^3,
                            'data': temporal data such as flow fields
        :type group: str
        :param time_step: the time step associated with a field when dealing with temporal data; if 'None' provided but
                          the group is set to 'data', the data will be written to the zeroth time step ('data/0')
        :type time_step: list
        :return: None
        """
        # if we want to write something in data, but we don't provide a time step, just write it to t = 0
        if group == DATA and time_step is None:
            logger.warning(f"No time step for group 'data' provided. Writing data to the zeroth time step '{DATA}/0'.")
            time_step = "0"

        # make sure that we write all snapshots to the temporal structure of DATA if a time step is given
        if time_step is not None or group == DATA:
            # if the group for data or the current time step doesn't exist yet, write it
            if self._data is None or str(time_step) not in self._file[DATA].keys():
                self._data = self._file.create_group(f"{DATA}/{time_step}")

            # set the correct group (time step), because once a temporal series is written, the group is set to the
            # last time step. if we now want to write a new field, we have to set the group to the correct time step
            else:
                self._data = self._file[f"{DATA}/{time_step}"]

            # write the data to HDF
            self._data.create_dataset(name, data=data)

        # do the same for the constant properties...
        elif group == CONST:
            if self._const is None:
                self._const = self._file.create_group(CONST)
            else:
                self._const = self._file[CONST]

            self._const.create_dataset(name, data=data)

        # ... and the grid
        elif group == GRID:
            if self._grid is None:
                self._grid = self._file.create_group(GRID)
            else:
                self._grid = self._file[GRID]

            self._grid.create_dataset(name, data=data)
        else:
            logger.critical(f"Unknown group type, available types are '{DATA}', '{CONST}' and '{GRID}'.")
            exit()

    def write_xdmf_file(self) -> None:
        """
        write an XDMF file based on the contents of a given HDF5 file

        :return: None
        """
        # check if an HDF file exists
        if not isfile(join(self._file_path, self._file_name)):
            logger.error(f"Could not find {join(self._file_path, self._file_name)}. Make sure the file exists and the "
                         f"provided path is correct.")
            exit(0)

        # if yes, generate an XDMF file based on the contents of the HDF5 file
        logger.info(f"Writing XDMF file for file {self._file_name}")
        xdmf_writer = XDMFWriter(self._file_path, self._file_name, mixed=self._mixed)
        xdmf_writer.write_xdmf()

    @property
    def mode(self) -> str:
        return self._mode

    @property
    def file_name(self) -> str:
        return self._file_name

    @mode.setter
    def mode(self, value) -> None:
        self._mode = value
        self._file = File(join(self._file_path, self._file_name), self._mode)


class XDMFWriter:
    """
    implements class for generating an XDMF file based on a given HDF5 file from S^3
    """
    def __init__(self, file_path: str, file_name: str, grid_name: str = "grid_s_cube", mixed: bool = False):
        """
        initializes the XDMFWriter class

        :param file_path: path to the HDF5 file for which the XDMF file should be created
        :type file_path: str
        :param file_name: name of the HDF5 file (incl. ending, e.g., data.h5)
        :type file_name: str
        :param grid_name: name of the grid (only used inside the XDMF)
        :type grid_name: str
        :param mixed: flag that the grid ist from type 'Mixed' (in case of unstructured grid which wasn't created with
                      S^3); only relevant for writing the XDMF file
        :type mixed: bool
        """
        self._file_path = file_path
        self._grid_name = grid_name
        self._mixed = mixed
        self._hdf_file_name = file_name
        self._file = File(join(self._file_path, self._hdf_file_name), "r")
        self._header = '<?xml version="1.0"?>\n<!DOCTYPE Xdmf SYSTEM "Xdmf.dtd" []>\n<Xdmf Version="2.0">\n'
        self._temporal_grid = False
        self._const_attributes = False
        self._keys_const_attributes = []

        # get the file name of the corresponding XDMF file
        self._xdmf_file_name = f"{self._hdf_file_name.split('.h5')[0]}.xdmf"

        # check if the grid is present and if all required keys exist, if not then we can't create the XDMF
        self._check_grid()

        # get the number of dimensions based on the coordinates of the grid
        self._n_dimensions = self._file.get(f"{GRID}/{CENTERS}")[()].shape[-1]
        self._n_cells = self._file.get(f"{GRID}/{CENTERS}")[()].shape[0]
        self._n_faces = self._file.get(f"{GRID}/{FACES}")[()].shape[0]
        self._n_vertices = self._file.get(f"{GRID}/{VERTICES}")[()].shape[0]

        # grid type and dimensions
        if self._mixed:
            self._grid_type = "Mixed"
        else:
            self._grid_type = "Quadrilateral" if self._n_dimensions == 2 else "Hexahedron"
        self._dims = "XY" if self._n_dimensions == 2 else "XYZ"

    def write_xdmf(self) -> None:
        """
        Implements a wrapper functions for writing the XDMF file

        :return: None
        """
        # 1. check if we have temporal data available
        self._temporal_grid = True if self._check_data() else False

        # 2. check what is available in const. to write ->> if we found something then it will be written into the
        # first time step of the temporal grid structure
        self._keys_const_attributes = self._get_const_keys()
        self._const_attributes = True if self._keys_const_attributes else False

        # write the XDMF file
        self._write_temporal_grid() if self._temporal_grid else self._write_const_grid()

    def _write_temporal_grid(self) -> None:
        """
        Write the XDMF file based on the temporal data within the HDF5 file, all fields which are time independent are
        written into the first time step

        :return: None
        """
        # header for temporal grid structure
        _domain_header = f'<Domain>\n<Grid Name="{self._grid_name}" GridType="Collection" CollectionType="temporal">\n'

        # write the corresponding XDMF file
        with open(join(self._file_path, self._xdmf_file_name), "w") as f_out:
            # write global header
            f_out.write(self._header)
            f_out.write(_domain_header)

            # loop over all available time steps and write all specified data to XDMF & HDF5 files, since we have the
            # HDMF5 file written completely for all specified snapshots, we can now iterate over all time steps
            for i, t in enumerate(sorted(self._file.get(DATA).keys(), key=lambda x: float(x))):
                # write grid specific header
                tmp = f'<Grid Name="{self._grid_name} {t}" GridType="Uniform">\n<Time Value="{t}"/>\n' \
                      f'<Topology TopologyType="{self._grid_type}" NumberOfElements="{self._n_faces}">\n' \
                      f'<DataItem Format="HDF" DataType="Int" Dimensions="{self._n_faces}'

                # the number of dimensions depends on the grid type
                tmp += '>\n' if self._mixed else f' {pow(2, self._n_dimensions)}">\n'
                f_out.write(tmp)

                # include the grid data from the HDF5 file
                f_out.write(f"{self._hdf_file_name}:/{GRID}/{FACES}\n")

                # write geometry part
                f_out.write(f'</DataItem>\n</Topology>\n<Geometry GeometryType="{self._dims}">\n'
                            f'<DataItem Rank="2" Dimensions="{self._n_vertices} {self._n_dimensions}" '
                            f'NumberType="Float" Precision="8" Format="HDF">\n')

                # write coordinates of vertices
                f_out.write(f"{self._hdf_file_name}:/{GRID}/{VERTICES}\n</DataItem>\n</Geometry>\n")

                # write everything we found in constant (fields) into the first time step
                if i == 0:
                    f_out.write(self._write_attributes())

                # loop over all fields available at each time step
                for k in self._file[f"{DATA}/{t}"].keys():
                    # assuming data is written out by s_cube as <field_name>_<position>, otherwise the name is taken
                    # as it is
                    _name = k.split("_")[0] if len(k.split("_")) > 1 else k

                    # determine if scalar or vector field
                    _shape = self._file.get(f"{DATA}/{t}/{k}")[()].shape
                    _second_dim = 1 if len(_shape) == 1 else _shape[1]

                    # in case our field is defined at the cell center
                    if _shape[0] == self._n_cells:
                        f_out.write(f'<Attribute Name="{_name}" AttributeType="Vector" Center="Cell">\n<DataItem '
                                    f'NumberType="Float" Precision="8" Format="HDF" '
                                    f'Dimensions="{self._n_cells} {_second_dim}">\n')
                        f_out.write(f"{self._hdf_file_name}:/{DATA}/{t}/{k}\n</DataItem>\n</Attribute>\n")

                    # if our field is located at the cell vertices
                    elif _shape[0] == self._n_vertices:
                        f_out.write(f'<Attribute Name="{_name}" AttributeType="Vector" Center="Node">\n<DataItem '
                                    f'NumberType="Float" Precision="8" Format="HDF" '
                                    f'Dimensions="{self._n_vertices} {_second_dim}">\n')
                        f_out.write(f"{self._hdf_file_name}:/{DATA}/{t}/{k}\n</DataItem>\n</Attribute>\n")

                    # we need to check if the field inside the temporal data matches our current field, because in
                    # contrast to the data inside constant, we didn't check here
                    else:
                        logger.warning(f"Field in '{DATA}/{t}/{k}' with a size of {_shape} doesn't match the number "
                                       f"of cells with N_cells = {self._n_cells} or the number of vertices with "
                                       f"N_vertices = {self._n_vertices}. Skipping this field.")
                        continue

                # write end tag of the current grid
                f_out.write('</Grid>\n')

            # write rest of file
            f_out.write('</Grid>\n</Domain>\n</Xdmf>')

    def _write_const_grid(self) -> None:
        """
        Write the XDMF file for the case of no temporal data being present in the HDF5 file

        :return: None
        """
        _grid_header = f'<Domain>\n<Grid Name="{self._grid_name}" GridType="Uniform">\n' \
                       f'<Topology TopologyType="{self._grid_type}" NumberOfElements="{self._n_faces}">\n' \
                       f'<DataItem Format="HDF" DataType="Int" Dimensions="{self._n_faces}'

        # the number of dimensions depends on the grid type
        _grid_header += '">\n' if self._mixed else f' {pow(2, self._n_dimensions)}">\n'

        # write the corresponding XDMF file
        with open(join(self._file_path, self._xdmf_file_name), "w") as f_out:
            # write global header
            f_out.write(self._header)
            f_out.write(_grid_header)

            # include the grid data from the HDF5 file
            f_out.write(f"{self._hdf_file_name}:/{GRID}/{FACES}\n")

            # write geometry part
            f_out.write(f'</DataItem>\n</Topology>\n<Geometry GeometryType="{self._dims}">\n'
                        f'<DataItem Rank="2" Dimensions="{self._n_vertices} {self._n_dimensions}" '
                        f'NumberType="Float" Precision="8" Format="HDF">\n')

            # write coordinates of vertices
            f_out.write(f"{self._hdf_file_name}:/{GRID}/{VERTICES}\n")

            # write end tags
            f_out.write("</DataItem>\n</Geometry>\n")

            # write the attributes found in constant
            f_out.write(self._write_attributes())

            # write rest of file
            f_out.write("</Grid>\n</Domain>\n</Xdmf>")

    def _write_attributes(self) -> str:
        """
        loop over all constant attributes we found and write them to the XDMF file

        :return: the string to write to the XDMF file containing all constant attributes
        :rtype: str
        """
        str_to_write = []
        for k in self._keys_const_attributes:
            _shape = self._file.get(f"{CONST}/{k}")[()].shape
            _second_dim = 1 if len(_shape) == 1 else _shape[1]

            if _shape[0] == self._n_cells:
                str_to_write.append(f'<Attribute Name="{k}" AttributeType="Vector" Center="Cell">\n<DataItem '
                                    f'NumberType="Float" Precision="8" Format="HDF" '
                                    f'Dimensions="{self._n_cells} {_second_dim}">\n'
                                    f'{self._hdf_file_name}:/{CONST}/{k}\n</DataItem>\n</Attribute>\n')

            elif _shape[0] == self._n_vertices:
                str_to_write.append(f'<Attribute Name="{k}" AttributeType="Vector" Center="Node">\n<DataItem '
                                    f'NumberType="Float" Precision="8" Format="HDF" '
                                    f'Dimensions="{self._n_vertices} {_second_dim}">\n'
                                    f'{self._hdf_file_name}:/{CONST}/{k}\n</DataItem>\n</Attribute>\n')

            # since we only added fields which match n_cells or n_vertices, this condition shouldn't be happening, but
            # just in case we missed something...
            else:
                logger.warning(f"Field in '{CONST}/{k}' with a size of {_shape} doesn't match the number of cells "
                               f"with N_cells = {self._n_cells} or the number of vertices with "
                               f"N_vertices = {self._n_vertices}. Skipping this field.")
                continue

        return "".join(str_to_write)

    def _get_const_keys(self) -> list:
        """
        check if any fields are available in the constant group of the HDF5 file

        :return: a list with all available fields, if nothing is found, an empty list is returned
        :rtype: list
        """
        if CONST in self._file.keys():
            # loop over all entries in const. and add everything, which has the same dimensions as we have number of
            # cells -> means we have some sort of field
            keys = []
            for k in self._file[CONST].keys():
                tmp = self._file.get(f"{CONST}/{k}")[()]
                if not tmp.shape:
                    continue
                elif self._n_cells == tmp.shape[0] or self._n_vertices == tmp.shape[0]:
                    keys.append(k)
        else:
            logger.info("Couldn't find any constant fields to write.")
            keys = []
        return keys

    def _check_data(self) -> bool:
        """
        Check if we have temporal data available in the HDF5 file

        :return: True if available else False
        :rtype: bool
        """
        return DATA in self._file.keys()

    def _check_grid(self) -> None:
        """
        Check if a grid (and all parts of it) inside the HDF5 file is present and if the keys match the defined keys
        for the cell centers, vertices and faces

        :return: None
        """
        if GRID in self._file.keys():
            if not FACES in self._file[GRID].keys():
                logger.error(f"Unable to find cell faces in group {GRID}. Make sure the key to the cell faces is "
                             f"present and named {FACES}.")
                exit(0)
            if not CENTERS in self._file[GRID].keys():
                logger.error(f"Unable to find cell centers in group {GRID}. Make sure the key to the cell centers is "
                             f"present and named {CENTERS}.")
                exit(0)
            if not VERTICES in self._file[GRID].keys():
                logger.error(f"Unable to find cell vertices in group {GRID}. Make sure the key to the cell vertices is"
                             f"present and named {VERTICES}.")
                exit(0)
        else:
            logger.error("Found no grid in the provided HDF5 file. Unable to create XDMF file.without a grid.")
            exit(0)


if __name__ == "__main__":
    pass
