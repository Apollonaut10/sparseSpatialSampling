"""
    interpolation of the CFD data for the specified fields and time steps onto the coarse grid, sampled with the S^3
    algorithm. Export the interpolated data to HDF5 and XDMF in order to be able to load them into Paraview
"""
import h5py
import logging
import torch as pt

from os.path import join
from sklearn.neighbors import KNeighborsRegressor

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class Fields:
    """
    class for storing each interpolated field at cell centers and cell nodes.
    """
    def __init__(self, centers: pt.Tensor = None, vertices: pt.Tensor = None):
        self.centers = centers
        self.vertices = vertices


class DataWriter:
    """
    class for interpolating the original CFD data onto the grid generated by the S^3 algorithm, handels the export
    of the data to HDF5 and XDMF.
    """
    def __init__(self, face_ids: pt.Tensor, nodes: pt.Tensor, centers: pt.Tensor, levels: pt.Tensor, save_dir: str,
                 domain_boundaries: list, save_name: str = "data_final_grid", grid_name: str = "final grid",
                 times: pt.Tensor = None) -> None:
        """

        :param face_ids: node indices of the leaf cells of the grid generated by the S^3 algorithm
        :param save_dir: directory to which the XDMF & HDF5 files should be saved to
        :param domain_boundaries: boundaries of the domain (or mask) used when executing the S^3 algorithm, compare to
                                  documentation in 'execute_grid_generation.execute_grid_generation()'
        :param save_name: HDF5 & XDMF file names
        :param grid_name: name of the grid (used inside XDMF)
        :param times: numerical time steps of the simulation
        """
        self._save_dir = save_dir
        self._save_name = save_name
        self._grid_name = grid_name
        self._centers = centers
        self._vertices = nodes
        self._levels = levels

        # face_id = node idx making up a face, e.g. [0, 1, 2, 3] make up a face of node no. 0-3
        self._face_id = face_ids
        self._n_vertices = self._vertices.size()[0]
        self._n_faces = self._face_id.size()[0]
        self.n_dimensions = self._centers.size()[1]
        self.times = times
        self.mesh_info = None

        # empty dict which stores the interpolated fields, created when calling the '_load_and_fit_data' method, if no
        # fields are specified all available fields will be interpolated onto the coarser mesh
        self._boundaries = domain_boundaries
        self._knn = KNeighborsRegressor(n_neighbors=8 if self.n_dimensions == 2 else 26, weights="distance")
        self._interpolated_fields = {}
        self._snapshot_counter = 0

    def write_data_to_file(self) -> None:
        """
        write the sampled grid and the fields, interpolated at the cell centers and nodes, respectively, to an HDF5
        file, the paths to the data and the structure of the grid for each time step is encoded in the XDMF file.

        :return: None
        """
        logger.info("Writing the data ...")
        _global_header = f'<?xml version="1.0"?>\n<!DOCTYPE Xdmf SYSTEM "Xdmf.dtd" []>\n<Xdmf Version="2.0">\n' \
                         f'<Domain>\n<Grid Name="{self._grid_name}" GridType="Collection" CollectionType="temporal">\n'
        _grid_type = "Quadrilateral" if self.n_dimensions == 2 else "Hexahedron"
        _dims = "XY" if self.n_dimensions == 2 else "XYZ"

        # create a writer and datasets for the grid
        _writer = h5py.File(join(self._save_dir, f"{self._save_name}.h5"), "w")
        _grid_data = _writer.create_group("grid")
        _grid_data.create_dataset("faces", data=self._face_id)
        _grid_data.create_dataset("vertices", data=self._vertices)

        # create group for each specified field, first add field for the cell levels
        _writer.create_dataset("levels", data=self._levels)

        for key in self._interpolated_fields.keys():
            _vertices = _writer.create_group(f"{key}_vertices")
            _center = _writer.create_group(f"{key}_center")

            # write the datasets for each time step
            for i, t in enumerate(self.times):
                # in case we have a scalar we need to remove the additional dimension we created for fitting the data
                if len(self._interpolated_fields[key].centers.squeeze().size()) == 2:
                    _center.create_dataset(str(t.item()), data=self._interpolated_fields[key].centers.squeeze()[:, i])
                    _vertices.create_dataset(str(t.item()), data=self._interpolated_fields[key].vertices.squeeze()[:, i])
                # in case we have a vector
                else:
                    _center.create_dataset(str(t.item()), data=self._interpolated_fields[key].centers[:, :, i])
                    _vertices.create_dataset(str(t.item()), data=self._interpolated_fields[key].vertices[:, :, i])

        # write global header of XDMF file
        with open(join(self._save_dir, f"{self._save_name}.xdmf"), "w") as f_out:
            f_out.write(_global_header)

        # loop over all available time steps and write all specified data to XDMF & HDF5 files
        for i, t in enumerate(self.times):
            with open(join(self._save_dir, f"{self._save_name}.xdmf"), "a") as f_out:
                # write grid specific header
                tmp = f'<Grid Name="{self._grid_name} {t}" GridType="Uniform">\n<Time Value="{t}"/>\n' \
                      f'<Topology TopologyType="{_grid_type}" NumberOfElements="{self._n_faces}">\n' \
                      f'<DataItem Format="HDF" DataType="Int" Dimensions="{self._n_faces} ' \
                      f'{pow(2, self.n_dimensions)}">\n'
                f_out.write(tmp)

                # include the grid data from the HDF5 file
                f_out.write(f"{self._save_name}.h5:/grid/faces\n")

            # write geometry part
            with open(join(self._save_dir, f"{self._save_name}.xdmf"), "a") as f_out:
                # write header for geometry
                f_out.write(f'</DataItem>\n</Topology>\n<Geometry GeometryType="{_dims}">\n'
                            f'<DataItem Rank="2" Dimensions="{self._n_vertices} {self.n_dimensions}" '
                            f'NumberType="Float" Format="HDF">\n')

                # write coordinates of vertices
                f_out.write(f"{self._save_name}.h5:/grid/vertices\n")

                # write end tags
                f_out.write("</DataItem>\n</Geometry>\n")

            # write the interpolated fields
            with open(join(self._save_dir, f"{self._save_name}.xdmf"), "a") as f_out:
                # write cell levels
                f_out.write(f'<Attribute Name="cell level" Center="Cell">\n<DataItem Format="HDF" Dimensions='
                            f'"{self._levels.size()[0]} {self._levels.size()[1]}">\n')
                f_out.write(f"{self._save_name}.h5:/levels\n")
                f_out.write("</DataItem>\n</Attribute>\n")

                for key in self._interpolated_fields.keys():
                    # determine 2nd dimension (scalar vs. vector)
                    if len(self._interpolated_fields[key].centers.size()) == 2:
                        _second_dim = 1
                    else:
                        _second_dim = self._interpolated_fields[key].centers.size()[1]

                    # write header
                    f_out.write(f'<Attribute Name="{key}" Center="Cell">\n<DataItem Format="HDF" Dimensions='
                                f'"{self._interpolated_fields[key].centers.size()[0]} {_second_dim}">\n')

                    # write interpolated field at cell center
                    f_out.write(f"{self._save_name}.h5:/{key}_center/{t}\n")
                    f_out.write("</DataItem>\n</Attribute>\n")

                    # then do the same for field at the vertices
                    f_out.write(f'<Attribute Name="{key}" Center="Node">\n<DataItem Format="HDF" Dimensions='
                                f'"{self._interpolated_fields[key].vertices.size()[0]} {_second_dim}">\n')
                    f_out.write(f"{self._save_name}.h5:/{key}_vertices/{t}\n")
                    f_out.write("</DataItem>\n</Attribute>\n")

                # write end tag of the current grid
                f_out.write('</Grid>\n')

        # write rest of file
        with open(join(self._save_dir, f"{self._save_name}.xdmf"), "a") as f_out:
            f_out.write('</Grid>\n</Domain>\n</Xdmf>')

        # close hdf file
        _writer.close()
        logger.info("Finished export.")

    def fit_data(self, _coord: pt.Tensor, _data: pt.Tensor, _field_name: str, _n_snapshots_total: int = None) -> None:
        """
        interpolate the CFD data executed on the original grid onto the newly, coarser grid generated by the S^3
        algorithm. The original field is interpolated at the cell centers as well as at the cell nodes.

        Note: the variables centers & vertices used in this method are denoting the values of the field at center and
        nodes of each cell (not the node coordinates of the generated mesh)

        :param _coord: the coordinates of the original grid used in CFD
        :param _data: the original field data
        :param _field_name: name of the field, which should be exported, e.g. 'p' for pressure field
        :param _n_snapshots_total: amount of snapshots in total, which should be exported. If 'None', it is assumed
                                   that the provided data are all available snapshots
        :return: None
        """
        # check if the field has the correct shape -> scalar fields need to be unsqueezed at dim=1 as:
        # [N_cells, N_dimensions, N_snapshots] (vector field) or [N_cells, 1, N_snapshots] (scalar field)
        assert len(_data.size()) == 3, "The provided field must have the shape '[N_cells, N_dimensions, N_snapshots]'" \
                                       "for a vector field and '[N_cells, 1, N_snapshots]' for a scalar field"

        # determine the required size of the data matrix
        _n_snapshots_total = _n_snapshots_total if _n_snapshots_total is not None else _data.size()[-1]

        # currently loaded number of snapshots
        _nc = _data.size()[-1]

        # add the data to the current field or create a new field if not yet existing
        if _field_name not in self._interpolated_fields:
            # reset the snapshot counter, because apparently we create a new field
            self._snapshot_counter = 0

            # instantiate field object
            self._interpolated_fields[_field_name] = Fields()

            # create empty tensors for the field values at centers & vertices with dimensions:
            # [N_cells, N_dimensions, N_snapshots_total]
            self._interpolated_fields[_field_name].centers = pt.zeros((self._centers.size()[0], _data.size()[1],
                                                                       _n_snapshots_total))
            self._interpolated_fields[_field_name].vertices = pt.zeros((self._vertices.size()[0], _data.size()[1],
                                                                        _n_snapshots_total))

        # create empty tensors for the values of the field at the centers & vertices with dimensions:
        # [N_cells, N_dimensions, N_snapshots_currently]
        centers = pt.zeros((self._centers.size()[0], _data.size()[1], _nc))
        vertices = pt.zeros((self._vertices.size()[0], _data.size()[1], _nc))

        # fit the KNN and interpolate the data, we need to predict each dimension separately (otherwise dim. mismatch)
        for dimension in range(_data.size()[1]):
            self._knn.fit(_coord, _data[:, dimension, :])
            centers[:, dimension, :_nc] = pt.from_numpy(self._knn.predict(self._centers))
            vertices[:, dimension, :_nc] = pt.from_numpy(self._knn.predict(self._vertices))

        # update the fields, for which snapshots we already executed the interpolation
        self._interpolated_fields[_field_name].centers[:, :, self._snapshot_counter:self._snapshot_counter + _nc] = centers
        self._interpolated_fields[_field_name].vertices[:, :, self._snapshot_counter:self._snapshot_counter + _nc] = vertices
        self._snapshot_counter += _nc


if __name__ == "__main__":
    pass
